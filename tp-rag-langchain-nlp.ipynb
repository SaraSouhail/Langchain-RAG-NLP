{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13907533,"sourceType":"datasetVersion","datasetId":8861126},{"sourceId":13907542,"sourceType":"datasetVersion","datasetId":8861134}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U langchain langchain-community langchain-core \\\n  langchain-text-splitters chromadb \\\n  sentence-transformers transformers\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:41.027874Z","iopub.execute_input":"2025-11-28T13:07:41.028783Z","iopub.status.idle":"2025-11-28T13:07:45.990700Z","shell.execute_reply.started":"2025-11-28T13:07:41.028747Z","shell.execute_reply":"2025-11-28T13:07:45.990008Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (1.1.0)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.4.1)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (1.1.0)\nRequirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (1.0.0)\nRequirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.3.5)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.1.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.57.3)\nRequirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.0.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.12.4)\nRequirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.0.0)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (25.0)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.15.0)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.4.2)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\nRequirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.4.0)\nRequirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.23.2)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.38.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.38.0)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.38.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.22.1)\nRequirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\nRequirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.0.0)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (34.1.0)\nRequirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.2.0)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\nRequirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\nRequirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\nRequirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\nRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (6.33.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\nRequirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\nRequirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\nRequirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport torch\n\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import Chroma\n\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\n\n# trandformers \nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline as hf_pipeline\nfrom langchain_community.llms import HuggingFacePipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:45.992544Z","iopub.execute_input":"2025-11-28T13:07:45.992910Z","iopub.status.idle":"2025-11-28T13:07:45.997864Z","shell.execute_reply.started":"2025-11-28T13:07:45.992885Z","shell.execute_reply":"2025-11-28T13:07:45.997173Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# chargement des pdfs ","metadata":{}},{"cell_type":"code","source":"def load_pdfs(pdf_paths):\n    \"\"\"\n    Charge plusieurs fichiers PDF et renvoie une liste de Documents.\n    Chaque page du PDF devient un Document (page_content + metadata).\n    \"\"\"\n    all_docs = []\n    for path in pdf_paths:\n        if not os.path.exists(path):\n            raise FileNotFoundError(f\"Fichier introuvable : {path}\")\n        print(f\" - Chargement du PDF : {path}\")\n        loader = PyPDFLoader(path)\n        docs = loader.load()\n        print(f\"   -> {len(docs)} pages chargées\")\n        all_docs.extend(docs)\n    print(f\"\\nTotal : {len(all_docs)} pages sur 1 ensemble des PDFs\\n\")\n    return all_docs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:45.999332Z","iopub.execute_input":"2025-11-28T13:07:45.999727Z","iopub.status.idle":"2025-11-28T13:07:46.013987Z","shell.execute_reply.started":"2025-11-28T13:07:45.999711Z","shell.execute_reply":"2025-11-28T13:07:46.013441Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# decoupage en chunks ","metadata":{}},{"cell_type":"code","source":"def split_documents(docs):\n    \"\"\"\n    Découpe les Documents (pages PDF) en chunks plus petits.\n    \"\"\"\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=800,        # taille max d'un chunk (en caractères)\n        chunk_overlap=200      # recouvrement\n    )\n    chunks = splitter.split_documents(docs)\n    print(f\"{len(chunks)} chunks créés après découpage\\n\")\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.014844Z","iopub.execute_input":"2025-11-28T13:07:46.015071Z","iopub.status.idle":"2025-11-28T13:07:46.032875Z","shell.execute_reply.started":"2025-11-28T13:07:46.015053Z","shell.execute_reply":"2025-11-28T13:07:46.032286Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# embbeding +chroma","metadata":{}},{"cell_type":"code","source":"def build_vectorstore(chunks, persist_directory: str = \"chroma_persist_db\"):\n    \"\"\"\n    Crée une base vectorielle Chroma à partir des chunks.\n    Utilise des embeddings SentenceTransformers.\n    \"\"\"\n    print(\"Construction de la base vectorielle (embeddings + Chroma)…\")\n\n    embeddings = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n    )\n\n    vectorstore = Chroma.from_documents(\n        documents=chunks,\n        embedding=embeddings,\n        persist_directory=persist_directory\n    )\n\n    print(\"Vectorstore prêt \\n\")\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.034329Z","iopub.execute_input":"2025-11-28T13:07:46.034869Z","iopub.status.idle":"2025-11-28T13:07:46.047891Z","shell.execute_reply.started":"2025-11-28T13:07:46.034851Z","shell.execute_reply":"2025-11-28T13:07:46.047273Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# prompt rag tres strict ","metadata":{}},{"cell_type":"code","source":"RAG_PROMPT_TEMPLATE = \"\"\"\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MEME langue que la QUESTION\n   (si la question est en français alors reponse en français,\n   si elle est en anglais alors reponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l’information n’est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\n{context}\nQUESTION_DE_L_UTILISATEUR =\n{question}\nR_PONSE (une seule langue, celle de la question) :\n\"\"\"\n\ndef build_prompt():\n    return PromptTemplate(\n        input_variables=[\"context\", \"question\"],\n        template= RAG_PROMPT_TEMPLATE\n    )\n\ndef format_docs(docs):\n    \"\"\"\n    Concatène le contenu des Documents en une seule chaîne de contexte.\n    \"\"\"\n    return \"\\n\\n\".join(doc.page_content for doc in docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.048508Z","iopub.execute_input":"2025-11-28T13:07:46.048676Z","iopub.status.idle":"2025-11-28T13:07:46.062378Z","shell.execute_reply.started":"2025-11-28T13:07:46.048662Z","shell.execute_reply":"2025-11-28T13:07:46.061808Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# llm open source fort ","metadata":{}},{"cell_type":"code","source":"def build_llm(model_name: str = \"Qwen/Qwen2.5-7B-Instruct\"):\n    \"\"\"\n    Construit un LLM open source fort (Qwen2.5-7B-Instruct)\n    via Transformers.\n    Nécessite une bonne machine GPU.\n    \"\"\"\n    print(f\"Chargement du modèle : {model_name} ...\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=\"auto\",\n        torch_dtype=torch.float16,\n    )\n\n    text_gen = hf_pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=256,\n        do_sample=False,\n        repetition_penalty=1.05\n    )\n\n    llm = HuggingFacePipeline(pipeline=text_gen)\n    print(\"LLM Qwen2.5-7B prêt \\n\")\n    return llm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.063809Z","iopub.execute_input":"2025-11-28T13:07:46.064325Z","iopub.status.idle":"2025-11-28T13:07:46.080653Z","shell.execute_reply.started":"2025-11-28T13:07:46.064307Z","shell.execute_reply":"2025-11-28T13:07:46.079999Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# chaine rag","metadata":{}},{"cell_type":"code","source":"def build_rag_chain(vectorstore, llm):\n    \"\"\"\n    Construit une chaîne RAG: question -> récupérer -> formatage du contexte ->\n    prompt -> LLM\n    \"\"\"\n    retrieved = vectorstore.as_retriever(\n        search_type=\"similarity\",\n        search_kwargs={\"k\": 4}  # nombre de chunks récupérés\n    )\n\n    prompt = build_prompt()\n\n    rag_chain = (\n        {\n            \"context\": retrieved | format_docs,\n            \"question\": RunnablePassthrough(),\n        }\n        | prompt\n        | llm\n    )\n\n    return rag_chain\n\ndef answer_question(rag_chain, question: str) -> str:\n    \"\"\"\n    Appelle la chaîne RAG sur une question donnée.\n    \"\"\"\n    return rag_chain.invoke(question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.081411Z","iopub.execute_input":"2025-11-28T13:07:46.081756Z","iopub.status.idle":"2025-11-28T13:07:46.095261Z","shell.execute_reply.started":"2025-11-28T13:07:46.081727Z","shell.execute_reply":"2025-11-28T13:07:46.094579Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# main : ","metadata":{}},{"cell_type":"code","source":"# MAIN\n\nprint(\"=== RAG LangChain + Qwen2.5-7B-Instruct + 2 PDF ===\\n\")\n\n# 1) Charger les PDF\nPDF_PATHS = [\n    \"/kaggle/input/pdf1-chapitre1/Chapitre1.pdf\" ,\n    \"/kaggle/input/pdf2-intronlp/IntroNLP.pdf\"\n]\ndocs = load_pdfs(PDF_PATHS)\n\n# 2) Découper en chunks\nchunks = split_documents(docs)\n\n# 3) Construire la base vectorielle\nvectorstore = build_vectorstore(chunks)\n\n# 4) LLM\nllm = build_llm()\n\n# 5) Chaîne RAG\nrag_chain = build_rag_chain(vectorstore, llm)\n\nprint(\"Tes deux PDF sont indexés.\")\n\nprint(\"Tape 'exit' pour quitter.\\n\")\n\nwhile True:\n    try:\n        question = input(\">>> Question :  \").strip()\n    except (EOFError, KeyboardInterrupt):\n        print(\"\\nAu revoir\")\n        break\n\n    if question.lower() in {\"exit\", \"quit\"}:\n        print(\"Au revoir\")\n        break\n\n    if not question:\n        continue\n\n    print(\"\\n[Assistant] Réponse en cours...\\n\")\n    try:\n        response = answer_question(rag_chain, question)\n        print(response)\n        print(\"\\n\" + \"-\" * 60 + \"\\n\")\n    except Exception as e:\n        print(\"Erreur lors de la génération de la réponse :\", e)\n        print(\"\\n\" + \"-\" * 60 + \"\\n\")\n\n# Extrait pour gestion d’erreur séparé (à ajouter si besoin)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T13:07:46.096073Z","iopub.execute_input":"2025-11-28T13:07:46.096642Z"}},"outputs":[{"name":"stdout","text":"=== RAG LangChain + Qwen2.5-7B-Instruct + 2 PDF ===\n\n - Chargement du PDF : /kaggle/input/pdf1-chapitre1/Chapitre1.pdf\n   -> 35 pages chargées\n - Chargement du PDF : /kaggle/input/pdf2-intronlp/IntroNLP.pdf\n   -> 37 pages chargées\n\nTotal : 72 pages sur 1 ensemble des PDFs\n\n76 chunks créés après découpage\n\nConstruction de la base vectorielle (embeddings + Chroma)…\nVectorstore prêt \n\nChargement du modèle : Qwen/Qwen2.5-7B-Instruct ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae69f453e4fe494a86b8be163202fb33"}},"metadata":{}},{"name":"stderr","text":"WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"LLM Qwen2.5-7B prêt \n\nTes deux PDF sont indexés.\nTape 'exit' pour quitter.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":">>> Question :   C'est quoi NLP ?\n"},{"name":"stdout","text":"\n[Assistant] Réponse en cours...\n\n\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MEME langue que la QUESTION\n   (si la question est en français alors reponse en français,\n   si elle est en anglais alors reponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l’information n’est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\nC’est quoi NLP\n2\nLe Traitement Automatique du Langage Naturel (TALN) ou Natural Language Processing (NLP) est \nune branche de l’intelligence artificielle qui vise à permettre aux machines de comprendre, interpréter, \ngénérer et interagir en langage humain, qu’il soit écrit ou oral.\n\nC’est quoi NLP\n2\nLe Traitement Automatique du Langage Naturel (TALN) ou Natural Language Processing (NLP) est \nune branche de l’intelligence artificielle qui vise à permettre aux machines de comprendre, interpréter, \ngénérer et interagir en langage humain, qu’il soit écrit ou oral.\n\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\n\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\nQUESTION_DE_L_UTILISATEUR =\nC'est quoi NLP ?\nR_PONSE (une seule langue, celle de la question) :\nLe Traitement Automatique du Langage Naturel (TALN) ou Natural Language Processing (NLP) est une branche de l'intelligence artificielle qui vise à permettre aux machines de comprendre, interpréter, générer et interagir en langage humain, qu'il soit écrit ou oral.\n\n------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":">>> Question :   C'est quoi LLM ?\n"},{"name":"stdout","text":"\n[Assistant] Réponse en cours...\n\n\n\nTu es un assistant RAG très STRICT.\n\nRègles OBLIGATOIRES :\n1. Tu utilises UNIQUEMENT le CONTEXTE ci-dessous (extraits des PDF).\n2. Tu réponds STRICTEMENT dans la MEME langue que la QUESTION\n   (si la question est en français alors reponse en français,\n   si elle est en anglais alors reponse en anglais, etc.).\n3. Tu NE DOIS PAS utiliser de connaissances externes.\n4. Si le contexte ne contient pas la réponse :\n   - tu dis que tu ne sais pas,\n   - tu précises que l’information n’est pas présente dans les PDF fournis,\n   - toujours dans la même langue que la question.\n\nCONTEXTE (extraits des PDF) :\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\n\nChapitre 1 : \nReprésentation des \ntextes\n01\n02\n03\n04\n\n22\nPhase d’apprentissage d’un modèle \nTransformer / LLM\nLes LLMs commencent par être entraînés sur des corpus massifs et variés, contenant :\n• des livres, \n• articles scientifiques, \n• sites web (Wikipedia, Reddit, blogs, forums),\n• des données multilingues,\n• parfois des codes sources (GitHub, StackOverflow),\n• et des documents spécialisés (juridiques, médicaux, etc. selon le modèle).\nObjectif : apprendre les règles du langage, et la syntaxe.\n\n22\nPhase d’apprentissage d’un modèle \nTransformer / LLM\nLes LLMs commencent par être entraînés sur des corpus massifs et variés, contenant :\n• des livres, \n• articles scientifiques, \n• sites web (Wikipedia, Reddit, blogs, forums),\n• des données multilingues,\n• parfois des codes sources (GitHub, StackOverflow),\n• et des documents spécialisés (juridiques, médicaux, etc. selon le modèle).\nObjectif : apprendre les règles du langage, et la syntaxe.\nQUESTION_DE_L_UTILISATEUR =\nC'est quoi LLM ?\nR_PONSE (une seule langue, celle de la question) :\nLLM signifie Large Language Model. C'est un type de modèle de langage qui commence par être entraîné sur des corpus massifs et variés, contenant des livres, articles scientifiques, sites web, données multilingues, parfois des codes sources, et des documents spécialisés. Son objectif est d'apprendre les règles du langage et la syntaxe. L'information sur ce qu'est exactement un LLM n'est pas présente dans les autres documents fournis. \n\nNote : La réponse est en français car la question est posée en français. Si la question était en anglais, la réponse serait en anglais. \n\nJe ne peux pas fournir plus de détails car les informations supplémentaires ne sont pas contenues dans le contexte fourni. Si vous avez d'autres questions basées uniquement sur le contexte donné, je serai ravi de vous aider. \n\nL'information sur ce qu'est exactement un LLM n'est pas présente dans les autres documents fournis. \n\nJe ne peux pas fournir plus de détails car les informations supplémentaires ne sont pas contenues dans le contexte fourni. Si vous avez d'autres questions basées uniquement sur le\n\n------------------------------------------------------------\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}