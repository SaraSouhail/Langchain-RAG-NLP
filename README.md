# LangChain RAG NLP â€“ Project README
## ğŸ“Œ Overview

This project demonstrates Retrieval-Augmented Generation (RAG) using LangChain, ChromaDB, and an openâ€‘source LLM (Qwen2.5â€‘7Bâ€‘Instruct). It loads PDF course materials, splits them into chunks, generates embeddings, stores them in a vector database, and answers user questions strictly based on the PDF content.

## ğŸš€ Features

Load multiple PDF documents

Smart chunking using RecursiveCharacterTextSplitter

Vector embeddings with SentenceTransformers

Vector storage using ChromaDB

Retrieval using similarity search

RAG chain based on LangChain

LLM inference using Qwen2.5â€‘7Bâ€‘Instruct

Works in Kaggle Notebook with GPU P100

## ğŸ“ Project Structure
```bash
project/
â”‚-- tp-rag-langchain-nlp.ipynb
â”‚-- README.md
```
## ğŸ“„ Requirements

Install dependencies:
```bash
!pip install -U langchain langchain-community langchain-core \
  langchain-text-splitters chromadb \
  sentence-transformers transformers
```
## ğŸ”§ How It Works
### 1. Load PDFs

Using PyPDFLoader, the project loads and extracts pages as LangChain Documents.

### 2. Chunking

Documents are split into overlapping chunks:

chunk_size = 800

chunk_overlap = 200

### 3. Embeddings

SentenceTransformers model:

sentence-transformers/all-MiniLM-L6-v2
### 4. Vector Store

ChromaDB creates a persistent vectorstore using embeddings.

### 5. RAG Chain

The retrieval + LLM pipeline:

Retrieve top-k relevant chunks

Format them into a strict RAG prompt

Generate answer using Qwen2.5â€‘7Bâ€‘Instruct

## â–¶ï¸ Usage

Run the notebook, then ask questions interactively:

>>> Question : Qu'est-ce que le NLP ?
>>> Question : Explain transformers architecture.
>>> Question : exit
## ğŸ“Œ RAG Rules (Strict)

The model must:

Answer only using the PDF context

Answer in the same language as the question

Say "I don't know" when the answer is not in the PDFs

## ğŸ”® Future Improvements

Add hybrid or MMR retrieval

Add metadata-based filtering

Try with larger embedding models

Evaluate RAG performance (precision & recall)

## ğŸ§‘â€ğŸ’» Author

SARA â€“ Master student in AI & Emerging Technologies

Project developed as part of NLP LLM/RAG coursework.

## â­ Support

If you use this repo, don't forget to star â¤ï¸ it on GitHub!
